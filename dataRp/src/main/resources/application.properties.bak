#部署相关的变量
#数据库

database.url=100.4.13.4:3306
database.username=root
database.password = root_123
#单点登录地址
de.server.host = http://100.4.16.20:8443


#智慧高新节点地址、前端端口号、后端端口号
zhgx.web.url= https://192.168.76.198
zhgx.service.url= https://192.168.77.101
zhgx.web.port=8088
zhgx.service.port = 8086

#系统超级管理员roleId
zhgx.admin.roleId = 20180910100433650

#kafka地址
spring.kafka.bootstrap-servers =100.4.16.20:9092


spring.application.name = zhgx
server.port=8086
server.swagger.context-path=/
gop.websocket.service-id=${spring.application.name}

spring.servlet.multipart.max-file-size=101Mb  
spring.servlet.multipart.max-request-size=200Mb 

# DB jdbc_config datasource
spring.datasource.master.driver-class-name = com.mysql.jdbc.Driver
spring.datasource.jdbc-url = jdbc:mysql://${database.url}/report_data?autoReconnect=true&useUnicode=true&characterEncoding=UTF-8&useSSL=false&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&useServerPrepStmts=false&allowMultiQueries=true
spring.datasource.username = ${database.username}
spring.datasource.password = ${database.password}


# datasource config
spring.datasource.type=com.zaxxer.hikari.HikariDataSource
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.auto-commit=true
spring.datasource.hikari.idle-timeout=10000
spring.datasource.hikari.pool-name=DatebookHikariCP
spring.datasource.hikari.max-lifetime=20000
spring.datasource.hikari.connection-timeout=10000
spring.datasource.hikari.connection-test-query=SELECT 1

#dao
mapper.scan.basePackage=com.h3c.bigdata.zhgx.function.*.dao
mybatis.configuration.map-underscore-to-camel-case=true
#解决查询结果中参数为null，参数名都不会返回的问题
mybatis.configuration.call-setters-on-nulls=true

#mybatis-plus.mapper-locations=classpath:/com/h3c/mapper/xml/*Mapper.xml
mybatis-plus.typeAliasesPackage=com.h3c.bigdata.zhgx.function.*.entity ,com.h3c.bigdata.zhgx.function.report.model

pagehelper.helperDialect=mysql
pagehelper.reasonable=false
pagehelper.supportMethodsArguments=true
pagehelper.params=count=countSql

# Log
logging.file=zhgx.log
logging.level.com.bigdata.zhgx=INFO
logging.level.org.springframework=ERROR
#print sql
logging.level.com.h3c.bigdata.zhgx.mapper=INFO


#cas
#cas服务地址
cas.server.host.url=${de.server.host}/cas

#登录地址
cas.server.host.login_url=/login
#注销地址
cas.server.host.logout_url = /logout

#单点登录前端地址
#web地址
web.url = ${zhgx.web.url}:${zhgx.web.port}/

#单点登录后台地址
#本应用访问地址
app.server.host.url = ${zhgx.service.url}:${zhgx.service.port}/login
#本应用登录地址
app.login.url = /login
#本应用退出地址
app.logout.url = /logout

#token 失效时间 默认30分钟
token.invalid = 1800000
#是否支持一个账号同一时间只允许一人登录
login.only = false

#填报系统常量
numReg=^[0-9]*$
lwxs=^([0-9]{1,}[.][0-9]*)$
enumType=4
dateType=3
#初始化密码规则
pass.word.rule=@gxq

#kafka配置
#生产者的配置，大部分我们可以使用默认的，这里列出几个比较重要的属性
#每批次发送消息的数量
spring.kafka.producer.batch-size =1000
#设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
spring.kafka.producer.retries = 0
#producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
spring.kafka.producer.buffer-memory = 33554432
#key序列化方式
spring.kafka.producer.key-serializer = org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer = org.apache.kafka.common.serialization.StringSerializer
#消费者的配置
#Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
spring.kafka.consumer.auto-offset-reset = latest
#是否开启自动提交
spring.kafka.consumer.enable-auto-commit = true
#自动提交的时间间隔
spring.kafka.consumer.auto-commit-interval = 10000
#key的解码方式
spring.kafka.consumer.key-deserializer = org.apache.kafka.common.serialization.StringDeserializer
#value的解码方式
spring.kafka.consumer.value-deserializer = org.apache.kafka.common.serialization.StringDeserializer
#在/usr/local/etc/kafka/consumer.properties中有配置
spring.kafka.consumer.group-id = rcms569866-zjk-consumer-group


kafka.app.topic.foo=TOPIC_SYNC_MIDDLE_GROUND
kafka.app.topic.user = TOPIC_SYNC_RESOURCECATALS
#ES
spring.es.node.cluster= zhgx_es
#spring.es.node.address=10.253.100.148
spring.es.node.address=100.4.13.4
spring.es.node.port= 9300


#最大查询数量
indexMaxResultCount = 20000000

#swagger配置
swagger.enabled = true
app.login.url.index=swagger-ui.html
cas.login = false
#系统超级管理员admin初始密码
zhgx.admin.password =admin@123

#file upload
uploadPath=c:\\upload\\
aesPath=c:\\upload\\aes\\
#uploadPath=/opt/annex-upload/
#aesPath=/opt/annex-upload/aes/
net_url=http://100.4.13.4:8087/doc/

#AES
enKey=hKrBL1SrZm7Pwqg8Z2kIyA==
#tomcat_cache_dir
server.tomcat.basedir=/opt/h3c/tmp

admin_old_passwd=$2a$10$n9cvZhDLS/V0HLKQJb5XxeVYsxxSBanmiUmKH6/8ggS33jbl4rmMe

#Date word
date_word=jydate
volume_word=volume